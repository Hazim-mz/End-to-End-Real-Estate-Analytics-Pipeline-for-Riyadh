{"timestamp":"2025-07-21T01:12:17.813134","level":"info","event":"DAG bundles loaded: dags-folder","logger":"airflow.dag_processing.bundles.manager.DagBundlesManager"}
{"timestamp":"2025-07-21T01:12:17.813877","level":"info","event":"Filling up the DagBag from /opt/airflow/dags/etl_pipeline_v2.py","logger":"airflow.models.dagbag.DagBag"}
{"timestamp":"2025-07-21T01:12:18.502411","level":"warning","event":"Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.","category":"FutureWarning","filename":"/opt/airflow/dags/etl_pipeline_v2.py","lineno":57,"logger":"py.warnings"}
{"timestamp":"2025-07-21T01:12:18.521783","level":"info","event":"Successfully connected to PostgreSQL database","logger":"loader"}
{"timestamp":"2025-07-21T01:12:18.548272","level":"info","event":"Database tables created successfully","logger":"loader"}
{"timestamp":"2025-07-21T01:12:18.548532","level":"info","event":"Tables created successfully","logger":"loader"}
{"timestamp":"2025-07-21T01:12:18.560795","level":"info","event":"Successfully batch upserted 9 properties to database from DataFrame","logger":"loader"}
{"timestamp":"2025-07-21T01:12:18.561677","level":"info","event":"Database connection closed","logger":"loader"}
{"timestamp":"2025-07-21T01:12:18.562427Z","level":"info","event":"Loaded 9 properties into database","chan":"stdout","logger":"task"}
{"timestamp":"2025-07-21T01:12:18.562758","level":"info","event":"Done. Returned value was: 9","logger":"airflow.task.operators.airflow.providers.standard.operators.python.PythonOperator"}
{"timestamp":"2025-07-21T01:12:18.563026","level":"info","event":"Pushing xcom","ti":"RuntimeTaskInstance(id=UUID('01982a87-bf9d-7017-8fc4-a69ede9535bf'), task_id='load', dag_id='realestate_etl_pipeline_v2', run_id='manual__2025-07-21T01:09:55.965044+00:00', try_number=1, map_index=-1, hostname='d9baf7fb2a61', context_carrier=None, task=<Task(PythonOperator): load>, bundle_instance=LocalDagBundle(name=dags-folder), max_tries=1, start_date=datetime.datetime(2025, 7, 21, 1, 12, 17, 760365, tzinfo=TzInfo(UTC)), end_date=None, is_mapped=False)","logger":"task"}
